{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 媒体与认知 Ch7\n",
    "RNN：numpy 实现 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################################################\n",
    "## Part 1: Prapare dataset and the sigmoid function ########\n",
    "############################################################\n",
    "\n",
    "# prepare the dataset\n",
    "# max dim of binary numbers we use (also the sequence length)\n",
    "max_dim = 8\n",
    "# store binary numbers in a look-up table X\n",
    "X = np.unpackbits(np.array([range(2**max_dim)],dtype=np.uint8).T,axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 媒体与认知 Ch7\n",
    "CNN：numpy 实现 mnist 识别"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import random\n",
    "from utils import Net, NLLLoss, SGD, get_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of training data is  (60000, 784)\n",
      "The shape of training label is  (60000,)\n",
      "The shape of testing data is  (10000, 784)\n",
      "The shape of testing label is  (10000,)\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(1) Load MNIST Dataset\n",
    "'''\n",
    "## load dataset\n",
    "def load():\n",
    "    with open(\"mnist.pkl\",'rb') as f:\n",
    "        mnist = pickle.load(f)\n",
    "    return mnist['training_images'], mnist['training_labels'], mnist['test_images'], mnist['test_labels']\n",
    "\n",
    "X_train, Y_train, X_test, Y_test = load()\n",
    "print('The shape of training data is ', X_train.shape)\n",
    "print('The shape of training label is ', Y_train.shape)\n",
    "print('The shape of testing data is ', X_test.shape)\n",
    "print('The shape of testing label is ', Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2aaebc3a358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## show the 1st image and label\n",
    "def show(x,y,K):\n",
    "    plt.figure(\"Image\")\n",
    "    plt.imshow(np.reshape(x[K,:],[28,28]))\n",
    "    plt.title(['label:', y[K]])\n",
    "    plt.show()\n",
    "\n",
    "show(X_train,Y_train,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The range of data is [0,255]\n",
      "The type of data is uint8\n",
      "The range of data is [-1.000000,1.000000]\n",
      "The type of data is float64\n",
      "The range of data is [0,255]\n",
      "The type of data is uint8\n",
      "The range of data is [-1.000000,1.000000]\n",
      "The type of data is float64\n"
     ]
    }
   ],
   "source": [
    "## normalize images\n",
    "def normalize(x):\n",
    "    print('The range of data is [%d,%d]' % (x.min(), x.max()))\n",
    "    print('The type of data is %s' % (x.dtype))\n",
    "    # COMPLETE\n",
    "    # rearrange x to [-1,1]\n",
    "    x = (x-x.min()) / x.max()*2 - 1\n",
    "    print('The range of data is [%f,%f]' % (x.min(), x.max()))\n",
    "    print('The type of data is %s' % (x.dtype))\n",
    "    return x\n",
    "\n",
    "X_train = normalize(X_train)\n",
    "X_test = normalize(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 4 1 9 2 1 3 1 4]\n",
      "[[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 0. 1.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]]\n",
      "[0 4 1 9 2 1 3 1 4]\n"
     ]
    }
   ],
   "source": [
    "## convert label to one-hot codes\n",
    "D_in = X_train.shape[-1] # 784\n",
    "D_out = 10\n",
    "def label2OH(y,D_out):\n",
    "    N = y.shape[0]\n",
    "    OH = np.zeros((N,D_out))\n",
    "    OH[np.arange(N), y] = 1\n",
    "    return OH\n",
    "\n",
    "def OH2label(OH):\n",
    "    y = np.argmax(OH, axis=1)\n",
    "    return y\n",
    "\n",
    "OH_train = label2OH(Y_train,D_out)\n",
    "OH_test = label2OH(Y_test,D_out)\n",
    "\n",
    "## check whether there is sth. wrong with OH\n",
    "if not OH_train[0,Y_train[0]] or OH2label(OH_train)[0] != Y_train[0]:\n",
    "    print('Something wrong with OH[0]!')\n",
    "\n",
    "y = Y_train[1:10]\n",
    "oh = label2OH(y, 10)\n",
    "print(y)\n",
    "print(oh)\n",
    "y = OH2label(oh)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ReLU error:  5.3765621223931464e-11\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(2) Construct Model\n",
    "'''\n",
    "## ReLU activation layer\n",
    "class ReLU():\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "\n",
    "    def _forward(self, x):\n",
    "        out = np.maximum(0,x)\n",
    "        self.input = x\n",
    "        return out\n",
    "\n",
    "    def _backward(self, d):\n",
    "        dX = d*((self.input)>0)\n",
    "\n",
    "        return dX\n",
    "    \n",
    "## check implementation of ReLU by numerial approximation\n",
    "delta =1e-6\n",
    "x = np.random.randn(8,10)\n",
    "e = np.random.randn(8,10)\n",
    "relu_test = ReLU()\n",
    "y = relu_test._forward(x)\n",
    "d = relu_test._backward(e)\n",
    "d_approx = (relu_test._forward(x+delta*e) - relu_test._forward(x)) / delta\n",
    "error = np.abs(d - d_approx).mean() / np.abs(d_approx).mean()\n",
    "print('ReLU error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Softmax error:  4.113389936168737e-07\n"
     ]
    }
   ],
   "source": [
    "## Softmax activation layer\n",
    "class Softmax():\n",
    "    def __init__(self):\n",
    "        self.input = None\n",
    "        self.output = None\n",
    "\n",
    "    def _forward(self, X):\n",
    "        Y = np.exp(X - np.tile(X.max(axis=1).reshape([X.shape[0],1]), X.shape[1]))\n",
    "        Z = Y / np.tile(np.sum(Y, axis=1).reshape([Y.shape[0],1]), Y.shape[1])\n",
    "        self.input = X\n",
    "        self.output = Z\n",
    "        return Z # distribution\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.input\n",
    "        Z = self.output\n",
    "        dX = np.zeros(X.shape)\n",
    "        N = Z.shape[0]\n",
    "        for n in range(N):\n",
    "            J = - np.dot(Z[n,:].reshape([Z.shape[1],1]), Z[n,:].reshape([1,Z.shape[1]])) + np.diag(Z[n,:])\n",
    "            dX[n,:] = np.dot(J,dout[n,:])\n",
    "        return dX\n",
    "\n",
    "## check implementation of Softmax by numerial approximation\n",
    "delta =1e-6\n",
    "x = np.random.randn(8,10)\n",
    "e = np.random.randn(8,10)\n",
    "sm_test = Softmax()\n",
    "y = sm_test._forward(x)\n",
    "d = sm_test._backward(e)\n",
    "d_approx = (sm_test._forward(x+delta*e) - sm_test._forward(x)) / delta\n",
    "error = np.abs(d - d_approx).mean() / np.abs(d_approx).mean()\n",
    "print('Softmax error: ', error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Fully connected layer\n",
    "class FC():\n",
    "    def __init__(self, D_in, D_out):\n",
    "        self.input = None\n",
    "        self.W = {'val': np.random.normal(0.0, np.sqrt(2/D_in), (D_in,D_out)), 'grad': 0}\n",
    "        self.b = {'val': np.random.randn(D_out), 'grad': 0}\n",
    "\n",
    "    def _forward(self, X):\n",
    "        out = np.dot(X, self.W['val']) + self.b['val']\n",
    "        self.input = X\n",
    "        return out\n",
    "\n",
    "    def _backward(self, dout):\n",
    "        X = self.input\n",
    "        dX = np.dot(dout, self.W['val'].T).reshape(X.shape)\n",
    "        self.W['grad'] = np.dot(np.sum(X,axis=1).T / X.shape[0], dout)\n",
    "        self.b['grad'] = dout.mean(axis=0)\n",
    "        return dX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Simple 2 layer NN\n",
    "class SimpleNet(Net):\n",
    "    def __init__(self, D_in, H, D_out, weights=''):\n",
    "        self.FC1 = FC(D_in, H)\n",
    "        self.ReLU1 = ReLU()\n",
    "        self.FC2 = FC(H, D_out)\n",
    "\n",
    "        if weights == '':\n",
    "            pass\n",
    "        else:\n",
    "            with open(weights,'rb') as f:\n",
    "                params = pickle.load(f)\n",
    "                self.set_params(params)\n",
    "\n",
    "    def forward(self, X):\n",
    "        h1 = self.FC1._forward(X)\n",
    "        a1 = self.ReLU1._forward(h1)\n",
    "        h2 = self.FC2._forward(a1)\n",
    "        return h2\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout = self.FC2._backward(dout)\n",
    "        dout = self.ReLU1._backward(dout)\n",
    "        dout = self.FC1._backward(dout)\n",
    "\n",
    "    def get_params(self):\n",
    "        return [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b]\n",
    "\n",
    "    def set_params(self, params):\n",
    "        [self.FC1.W, self.FC1.b, self.FC2.W, self.FC2.b] = params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Cross Entropy Loss\n",
    "class CrossEntropyLoss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def get(self, Y_pred, Y_true):\n",
    "        N = Y_pred.shape[0]\n",
    "        softmax = Softmax()\n",
    "        prob = softmax._forward(Y_pred)\n",
    "        loss = NLLLoss(prob, Y_true)\n",
    "        Y_serial = np.argmax(Y_true, axis=1)\n",
    "        dout = prob.copy()\n",
    "        dout[np.arange(N), Y_serial] -= 1\n",
    "        return loss, dout\n",
    "\n",
    "## build simple model\n",
    "H = 300\n",
    "model = SimpleNet(D_in, H, D_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 0\n",
      "TRAIN SET ACC: 11920 / 60000 = 0.19866666666666666\n",
      "TEST SET ACC: 2049 / 10000 = 0.2049\n",
      "EPOCH 1\n",
      "TRAIN SET ACC: 16566 / 60000 = 0.2761\n",
      "TEST SET ACC: 2861 / 10000 = 0.2861\n",
      "EPOCH 2\n",
      "TRAIN SET ACC: 23957 / 60000 = 0.3992833333333333\n",
      "TEST SET ACC: 4043 / 10000 = 0.4043\n",
      "EPOCH 3\n",
      "TRAIN SET ACC: 28613 / 60000 = 0.4768833333333333\n",
      "TEST SET ACC: 4808 / 10000 = 0.4808\n",
      "EPOCH 4\n",
      "TRAIN SET ACC: 19391 / 60000 = 0.3231833333333333\n",
      "TEST SET ACC: 3162 / 10000 = 0.3162\n",
      "FINAL TEST\n",
      "TRAIN SET ACC: 19391 / 60000 = 0.3231833333333333\n",
      "TEST SET ACC: 3162 / 10000 = 0.3162\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "(3) Training\n",
    "'''\n",
    "## Evaluation\n",
    "def evaluation(model,X,Y):\n",
    "    pred = model.forward(X)\n",
    "    result = OH2label(pred) == Y\n",
    "    result = list(result)\n",
    "    return result.count(1), X.shape[0]\n",
    "\n",
    "optim = SGD(model.get_params(), lr=0.0001, reg=0.00003)\n",
    "criterion = CrossEntropyLoss()\n",
    "\n",
    "batch_size = 64\n",
    "EPOCH = 5\n",
    "BATCH = int(X_train.shape[0] / batch_size)\n",
    "for e in range(EPOCH):\n",
    "    ## shuffle data\n",
    "    index = [i for i in range(X_train.shape[0])]\n",
    "    random.shuffle(index)\n",
    "    X_train = X_train[index,:]\n",
    "    Y_train = Y_train[index]\n",
    "\n",
    "    for b in range(BATCH):\n",
    "        ## get batch, covert to one-hot\n",
    "        X_batch, Y_batch = get_batch(X_train, Y_train, batch_size, b)\n",
    "        OH_batch = label2OH(Y_batch, D_out)\n",
    "\n",
    "        ## forward, loss, backward, update weights\n",
    "        pred = model.forward(X_batch)\n",
    "        loss, dout = criterion.get(pred, OH_batch)\n",
    "        model.backward(dout)\n",
    "        optim.step()\n",
    "\n",
    "    print(\"EPOCH %d\" % (e))\n",
    "    # TRAIN SET ACC\n",
    "    correct_num, total_num = evaluation(model,X_train,Y_train)\n",
    "    print(\"TRAIN SET ACC: \" + str(correct_num) + \" / \" + str(total_num) + \" = \" + str(correct_num/total_num))\n",
    "\n",
    "    # TEST SET ACC\n",
    "    correct_num, total_num = evaluation(model,X_test,Y_test)\n",
    "    print(\"TEST SET ACC: \" + str(correct_num) + \" / \" + str(total_num) + \" = \" + str(correct_num/total_num))\n",
    "\n",
    "## save weights\n",
    "weights = model.get_params()\n",
    "with open(\"weights.pkl\",\"wb\") as f:\n",
    "    pickle.dump(weights, f)\n",
    "\n",
    "## load weights and test\n",
    "model = SimpleNet(D_in, H, D_out, \"weights.pkl\")\n",
    "print(\"FINAL TEST\")\n",
    "# TRAIN SET ACC\n",
    "correct_num, total_num = evaluation(model,X_train,Y_train)\n",
    "print(\"TRAIN SET ACC: \" + str(correct_num) + \" / \" + str(total_num) + \" = \" + str(correct_num/total_num))\n",
    "\n",
    "# TEST SET ACC\n",
    "correct_num, total_num = evaluation(model,X_test,Y_test)\n",
    "print(\"TEST SET ACC: \" + str(correct_num) + \" / \" + str(total_num) + \" = \" + str(correct_num/total_num))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 媒体与认知 Ch6\n",
    "基于SVM的图像分类"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------- kernel: linear ---------------\n",
      "C =  0.01\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n",
      "C =  0.1\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n",
      "C =  0.5\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n",
      "C =  1.0\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n",
      "C =  3.0\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n",
      "C =  10.0\n",
      "SVM-training accuracy: 1.0\n",
      "SVM-testing accuracy 0.9151832460732985\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27ce73557b8>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "import numpy as np\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 装载数据\n",
    "data = sio.loadmat('homework_ch6/Caltech-256_VGG_10classes.mat')\n",
    "traindata = data['traindata']\n",
    "testdata = data['testdata']\n",
    "\n",
    "# data['traindata'].shape=(1,1)\n",
    "# data['traindata'][0][0].shape=()\n",
    "# type(data['traindata'][0][0])=numpy.void\n",
    "# data['traindata'][0][0][0].shape=(4096,300)\n",
    "# type(data['traindata'][0][0][0])=numpy.ndarray\n",
    "x_train = traindata[0][0][0].transpose()  # 转置，shape=(300,4096)\n",
    "y_train = traindata[0][0][1].ravel()      # 将多维数组转换为一维数组，如果没有必要，不会产生源数据的副本\n",
    "x_test = testdata[0][0][0].transpose()\n",
    "y_test = testdata[0][0][1].ravel()\n",
    "\n",
    "# check if the data have been correctly loaded\n",
    "# print (x_train.shape)     # (300,4096)\n",
    "# print (y_train.shape)     # (300,)\n",
    "\n",
    "# 调用SVM，设置参数，请查看SVC的用法\n",
    "C = [0.01, 0.1, 0.5, 1.0, 3.0, 10.0]\n",
    "kernel = ['rbf', 'linear', 'poly', 'sigmoid']\n",
    "kernel = ['linear']\n",
    "#C = [0.0, 0.01, 0.1]  # coef0 for sigmoid\n",
    "for k in kernel:\n",
    "    print('--------------- kernel: '+ k +' ---------------')\n",
    "    train_accur = []\n",
    "    test_accur = []\n",
    "    for c in C:\n",
    "        model = svm.SVC(C = c, kernel=k)\n",
    "        print('C = ', c)\n",
    "        # 学习模型参数\n",
    "        model.fit(x_train,y_train)\n",
    "\n",
    "        # 输出识别准确率\n",
    "        accur = model.score(x_train,y_train)\n",
    "        train_accur = train_accur + [accur]\n",
    "        print (\"SVM-training accuracy :\", accur)\n",
    "        y_hat=model.predict(x_train)\n",
    "        # 计算训练集各类别的识别准确率，请根据准确率定义写出计算公式\n",
    "        #accur = np.sum(y_hat==y_train) / len(y_hat)\n",
    "        #print(\"SVM-training accuracy:\", accur)\n",
    "\n",
    "        accur = model.score(x_test,y_test)\n",
    "        test_accur = test_accur + [accur]\n",
    "        print (\"SVM-testing accuracy\", accur)\n",
    "        y_hat=model.predict(x_test)\n",
    "        # 计算测试集各类别的识别准确率，同上\n",
    "        #accur = np.sum(y_hat==y_test) / len(y_hat)\n",
    "        #print(\"SVM-training accuracy:\", accur)\n",
    "\n",
    "        print()\n",
    "\n",
    "    plt.plot(C,train_accur,label='train_'+k)\n",
    "    plt.plot(C,test_accur,label='test_'+k)\n",
    "\n",
    "plt.legend(loc = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
